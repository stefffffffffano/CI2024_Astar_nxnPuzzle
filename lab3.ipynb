{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple,deque\n",
    "from heapq import heappush, heappop\n",
    "from random import choice\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem framing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUZZLE_DIM = 9\n",
    "action = namedtuple('Action', ['pos1', 'pos2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def available_actions(state: np.ndarray) -> list['Action']:\n",
    "    x, y = [int(_[0]) for _ in np.where(state == 0)]\n",
    "    actions = list()\n",
    "    if x > 0:\n",
    "        actions.append(action((x, y), (x - 1, y)))\n",
    "    if x < PUZZLE_DIM - 1:\n",
    "        actions.append(action((x, y), (x + 1, y)))\n",
    "    if y > 0:\n",
    "        actions.append(action((x, y), (x, y - 1)))\n",
    "    if y < PUZZLE_DIM - 1:\n",
    "        actions.append(action((x, y), (x, y + 1)))\n",
    "    return actions\n",
    "\n",
    "\n",
    "\n",
    "def do_action(state: np.ndarray, action: 'Action') -> np.ndarray:\n",
    "    new_state = state.copy()\n",
    "    new_state[action.pos1], new_state[action.pos2] = new_state[action.pos2], new_state[action.pos1]\n",
    "    return new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Randomizing: 100%|██████████| 100000/100000 [00:00<00:00, 143617.63it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 3, 63, 69, 30, 35, 67, 38, 75,  8],\n",
       "       [79,  7, 10, 48, 52, 33, 72, 70, 16],\n",
       "       [43, 13, 62, 25, 19, 60, 58, 26, 31],\n",
       "       [ 9, 37, 65, 44, 27, 46, 41, 24, 59],\n",
       "       [34, 51,  4, 73, 50, 42, 49, 29,  2],\n",
       "       [ 6, 64, 36, 12, 71, 32, 15, 40, 74],\n",
       "       [28,  5, 53, 57, 78, 47, 14, 54, 55],\n",
       "       [23, 66, 77, 17, 80, 21, 76, 61, 11],\n",
       "       [22, 39, 56, 45,  0,  1, 18, 20, 68]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOMIZE_STEPS = 100_000\n",
    "state = np.array([i for i in range(1, PUZZLE_DIM**2)] + [0]).reshape((PUZZLE_DIM, PUZZLE_DIM))\n",
    "for r in tqdm(range(RANDOMIZE_STEPS), desc='Randomizing'):\n",
    "    state = do_action(state, choice(available_actions(state)))\n",
    "state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions + heuristics combined together\n",
    "If we are able not to overestimate the estimation in a minimization problem, then the optimum is guaranteed, but the number of states evaluated increases, resulting in more time needed to find a result.\n",
    "This is somehow acceptable for smaller instances (2x2 or 3x3), when reaching 4x4 or more, the optimum cannot be computed anymore if we want to do it in a reasonable time. Thus, we let on purpose the heuristic to overestimate (also a lot in case of 6x6 or 7x7), so that it is able to find a solution in a reasonable time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_solved(state: np.ndarray) -> bool:\n",
    "    return np.array_equal(state, np.array([i for i in range(1, PUZZLE_DIM**2)] + [0]).reshape((PUZZLE_DIM, PUZZLE_DIM)))\n",
    "\n",
    "class PuzzleHeuristicService:\n",
    "    def __init__(self, goal_state: np.ndarray):\n",
    "        self.goal_state = goal_state\n",
    "\n",
    "    def heuristic_manhattan_distance(self, position: np.ndarray) -> int:\n",
    "        distance = 0\n",
    "        size = len(position)\n",
    "        for i in range(size):\n",
    "            for j in range(size):\n",
    "                tile = position[i][j]\n",
    "                if tile != 0:\n",
    "                    target_row = (tile - 1) // size\n",
    "                    target_col = (tile - 1) % size\n",
    "                    distance += abs(i - target_row) + abs(j - target_col)\n",
    "        return distance\n",
    "\n",
    "    def heuristic_linear_conflict(self, position: np.ndarray) -> int:\n",
    "        conflict = 0\n",
    "        size = len(position)\n",
    "\n",
    "        # Row conflicts\n",
    "        for row in range(size):\n",
    "            max_val = -1\n",
    "            for col in range(size):\n",
    "                value = position[row][col]\n",
    "                if value != 0 and (value - 1) // size == row:\n",
    "                    if value > max_val:\n",
    "                        max_val = value\n",
    "                    else:\n",
    "                        conflict += 2\n",
    "\n",
    "        # Column conflicts\n",
    "        for col in range(size):\n",
    "            max_val = -1\n",
    "            for row in range(size):\n",
    "                value = position[row][col]\n",
    "                if value != 0 and (value - 1) % size == col:\n",
    "                    if value > max_val:\n",
    "                        max_val = value\n",
    "                    else:\n",
    "                        conflict += 2\n",
    "\n",
    "        return conflict\n",
    "\n",
    "    def heuristic_walking_distance(self, position: np.ndarray) -> int:\n",
    "        # Calculate the Manhattan distance grid\n",
    "        size = len(position)\n",
    "        distance_grid = [[0] * size for _ in range(size)]\n",
    "\n",
    "        for row in range(size):\n",
    "            for col in range(size):\n",
    "                value = position[row][col]\n",
    "                if value != 0:\n",
    "                    target_row = (value - 1) // size\n",
    "                    target_col = (value - 1) % size\n",
    "                    distance_grid[row][col] = abs(row - target_row) + abs(col - target_col)\n",
    "\n",
    "        # Sum the distances\n",
    "        walking_distance = sum(sum(row) for row in distance_grid)\n",
    "        return walking_distance\n",
    "    def compute_multiplication_factor(self) -> int:\n",
    "        if PUZZLE_DIM <= 5:\n",
    "            return 1\n",
    "        elif PUZZLE_DIM == 6:\n",
    "            return 2\n",
    "        else:\n",
    "            return 100_000\n",
    "\n",
    "    def combined_heuristic(self, position: np.ndarray) -> int:\n",
    "        return self.compute_multiplication_factor() * (\n",
    "            self.heuristic_manhattan_distance(position)\n",
    "            + self.heuristic_linear_conflict(position)\n",
    "            + self.heuristic_walking_distance(position)\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_with_enhanced_a_star(initial_state: np.ndarray, goal_state: np.ndarray) -> tuple[list, int]:\n",
    "    heuristic_service = PuzzleHeuristicService(goal_state)\n",
    "\n",
    "    def calculate_heuristic(state: np.ndarray) -> int:\n",
    "        return heuristic_service.combined_heuristic(state)\n",
    "\n",
    "    # Priority queue: (f_score, g_score, state_bytes, path)\n",
    "    open_set = []\n",
    "    heappush(open_set, (calculate_heuristic(initial_state), 0, initial_state.tobytes(), []))\n",
    "    visited = set()\n",
    "    goal_state_bytes = goal_state.tobytes()\n",
    "\n",
    "    counter_action_evaluated = 0\n",
    "\n",
    "    while open_set:\n",
    "        # Extract the node with the lowest f_score\n",
    "        f_score, g_score, current_bytes, path = heappop(open_set)\n",
    "        current_state = np.frombuffer(current_bytes, dtype=initial_state.dtype).reshape(initial_state.shape)\n",
    "\n",
    "        # Check if we've reached the goal state\n",
    "        if current_bytes == goal_state_bytes:\n",
    "            return path, counter_action_evaluated\n",
    "\n",
    "        # Add current state to visited\n",
    "        visited.add(current_bytes)\n",
    "\n",
    "        # Generate all possible moves\n",
    "        for act in available_actions(current_state):\n",
    "            counter_action_evaluated += 1\n",
    "            next_state = do_action(current_state, act)\n",
    "            next_bytes = next_state.tobytes()\n",
    "\n",
    "            if next_bytes in visited:\n",
    "                continue\n",
    "\n",
    "            # Update scores\n",
    "            new_g_score = g_score + 1\n",
    "            new_f_score = new_g_score + calculate_heuristic(next_state)\n",
    "\n",
    "            # Add new state to open set\n",
    "            heappush(open_set, (new_f_score, new_g_score, next_bytes, path + [act]))\n",
    "\n",
    "    return None, counter_action_evaluated  # No solution found\n",
    "\n",
    "goal_state = np.array([i for i in range(1, PUZZLE_DIM**2)] + [0]).reshape((PUZZLE_DIM, PUZZLE_DIM))\n",
    "path, evaluated_states = solve_with_enhanced_a_star(state, goal_state)\n",
    "print(\"Path to solution:\", path)\n",
    "print(\"Number of states evaluated:\", evaluated_states)\n",
    "print(\"Goodness of the solution: \"  + str(len(path)) + \" moves\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the puzzle solved? True\n",
      "[[ 1  2  3  4  5  6  7  8]\n",
      " [ 9 10 11 12 13 14 15 16]\n",
      " [17 18 19 20 21 22 23 24]\n",
      " [25 26 27 28 29 30 31 32]\n",
      " [33 34 35 36 37 38 39 40]\n",
      " [41 42 43 44 45 46 47 48]\n",
      " [49 50 51 52 53 54 55 56]\n",
      " [57 58 59 60 61 62 63  0]]\n"
     ]
    }
   ],
   "source": [
    "current_state = state.copy()\n",
    "for act in path:\n",
    "    current_state = do_action(current_state, act)\n",
    "print(\"Is the puzzle solved?\", is_solved(current_state))\n",
    "print(current_state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
